{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3C4Rj1DhqWg"
      },
      "source": [
        "Implement initial model training with scikit-learn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gytvXusPh0pz",
        "outputId": "999c1ef9-2896-46fc-f326-741ca82f2fce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "#Implement initial model training with scikit-learn\n",
        "try:\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "\n",
        "    print(\"Libraries imported successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error importing libraries: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARyxhVf3MrXl",
        "outputId": "91f65f29-408e-4007-928d-767f4b07aa52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data created successfully!\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Simple dataset: X = feature, y = target\n",
        "    X = np.array([[1], [2], [3], [4], [5]])\n",
        "    y = np.array([2, 4, 6, 8, 10])\n",
        "\n",
        "    print(\"Data created successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating data: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFrDTBHgNw1i",
        "outputId": "d934af59-64e8-41b1-a1c3-e131d6493e4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model trained successfully!\n",
            "θ0 (Intercept): 0.0\n",
            "θ1 (Coefficient): 2.0\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    model = LinearRegression()\n",
        "    model.fit(X, y)\n",
        "    print(\"Model trained successfully!\")\n",
        "    print(f\"θ0 (Intercept): {model.intercept_}\")\n",
        "    print(f\"θ1 (Coefficient): {model.coef_[0]}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during training: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4FgXDSzQsF5",
        "outputId": "c064615b-842d-4f07-8ab7-02fc69e6800c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction for X = 2.0 is Y = 4.0\n"
          ]
        }
      ],
      "source": [
        "# Assuming 'model' is already trained\n",
        "\n",
        "try:\n",
        "    # Example: Ask for input from user\n",
        "    x_value = float(input(\"Enter a value for X: \"))\n",
        "\n",
        "    # Reshape because sklearn expects 2D array for prediction\n",
        "    x_array = [[x_value]]\n",
        "\n",
        "    # Predict using trained model\n",
        "    y_pred = model.predict(x_array)\n",
        "\n",
        "    print(f\"Prediction for X = {x_value} is Y = {y_pred[0]}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during prediction: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZj1vVpwfcTx"
      },
      "source": [
        "Implement initial model training without scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9-orNLXfrcK",
        "outputId": "dd9e5bd5-3a41-4ead-e70d-43da15dcd475"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final ?0 (intercept): 0.09475321533750963\n",
            "Final ?1 (slope): 1.9737548787242036\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction for X = 4.0 is Y = 7.989772730234324\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step 1: Dataset\n",
        "X = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([2, 4, 6, 8, 10])\n",
        "m_samples = len(X)\n",
        "\n",
        "# Step 2: Initialize parameters\n",
        "theta_0 = 0  # Intercept\n",
        "theta_1 = 0  # Slope\n",
        "alpha = 0.01 # Learning rate\n",
        "iterations = 1000\n",
        "\n",
        "# Step 3: Gradient Descent Loop\n",
        "for _ in range(iterations):\n",
        "    # Hypothesis function h_theta(x)\n",
        "    y_pred = theta_0 + theta_1 * X\n",
        "\n",
        "    # Errors\n",
        "    error = y_pred - y\n",
        "\n",
        "    # Gradients (derivatives of cost w.r.t parameters)\n",
        "    d_theta0 = (1/m_samples) * np.sum(error)      # ?/??0 J(?)\n",
        "    d_theta1 = (1/m_samples) * np.sum(error * X)  # ?/??1 J(?)\n",
        "\n",
        "    # Update parameters using update rule\n",
        "    theta_0 -= alpha * d_theta0\n",
        "    theta_1 -= alpha * d_theta1\n",
        "\n",
        "# Step 4: Final Parameters\n",
        "print(f\"Final ?0 (intercept): {theta_0}\")\n",
        "print(f\"Final ?1 (slope): {theta_1}\")\n",
        "\n",
        "# Step 5: Prediction\n",
        "x_value = float(input(\"Enter a value for X: \"))\n",
        "y_prediction = theta_0 + theta_1 * x_value\n",
        "print(f\"Prediction for X = {x_value} is Y = {y_prediction}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "togZCHkA_zaA"
      },
      "source": [
        "Enhance data cleaning and tune epochs for accurate predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "dOSRN0DjCgMr",
        "outputId": "eb28ad62-be53-48e2-e243-40f5e51ad03a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n",
            "CSV loaded successfully!\n",
            "Data cleaned successfully!\n",
            "Z-score normalization done (original values preserved)!\n",
            "Data shuffled and split into training/testing sets!\n",
            "Training complete in 80 epochs\n",
            "?0 (intercept): -8.802595336650447e-05\n",
            "?1 (slope): 0.9997589485124853\n",
            "Test MSE (normalized space): 7.226075964522702e-08\n",
            "Predicted Y (original scale): 2.040406366369183\n"
          ]
        }
      ],
      "source": [
        "# ====== 1. IMPORT LIBRARIES ======\n",
        "import os\n",
        "try:\n",
        "    from model_storage import ModelStorage\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from tkinter import filedialog\n",
        "    import tkinter as tk\n",
        "    print(\"Libraries imported successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error importing libraries: {e}\")\n",
        "\n",
        "# Utility: choose by number OR exact name\n",
        "def choose_column(df: pd.DataFrame, prompt: str) -> str:\n",
        "    choice = input(prompt).strip()\n",
        "    if choice.isdigit():\n",
        "        idx = int(choice) - 1\n",
        "        if idx < 0 or idx >= len(df.columns):\n",
        "            raise ValueError(\"Column number out of range.\")\n",
        "        return df.columns[idx]\n",
        "    if choice not in df.columns:\n",
        "        raise ValueError(f\"Column name '{choice}' not in CSV columns.\")\n",
        "    return choice\n",
        "\n",
        "# ====== 2. LOAD CSV ======\n",
        "try:\n",
        "    # Create a Tkinter root window\n",
        "    root = tk.Tk()\n",
        "    root.withdraw()\n",
        "    root.attributes('-topmost', True)\n",
        "    root.update()\n",
        "    root.after(100)\n",
        "\n",
        "    # Open a file picker dialog to select the CSV file\n",
        "    file_name = filedialog.askopenfilename(filetypes=[(\"CSV files\", \"*.csv\")])\n",
        "    if not file_name:\n",
        "        raise FileNotFoundError(\"No file selected.\")\n",
        "    \n",
        "    # Read the CSV file using pandas\n",
        "    df = pd.read_csv(file_name)\n",
        "\n",
        "    print(\"\\nCSV loaded successfully!\")\n",
        "    print(f\"Using DB at: {os.path.abspath('1models.db')}\")\n",
        "    print(\"\\nAvailable columns:\")\n",
        "    for idx, col in enumerate(df.columns, 1):\n",
        "        print(f\"{idx}. {col}\")\n",
        "\n",
        "    # Ask user which columns to use (number OR name)\n",
        "    x_col = choose_column(df, \"\\nEnter the number OR name for X (Input feature): \")\n",
        "    y_col = choose_column(df, \"Enter the number OR name for Y (Target variable): \")\n",
        "\n",
        "    # Convert chosen columns to numeric, coercing invalid values to NaN\n",
        "    df[x_col] = pd.to_numeric(df[x_col], errors='coerce')\n",
        "    df[y_col] = pd.to_numeric(df[y_col], errors='coerce')\n",
        "    \n",
        "    # Remove rows with NaN\n",
        "    df = df.dropna(subset=[x_col, y_col])\n",
        "    if df.empty:\n",
        "        raise ValueError(\"No valid numeric data in selected columns after cleaning.\")\n",
        "    \n",
        "    print(f\"\\nSelected X: {x_col}, Y: {y_col}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading CSV: {e}\")\n",
        "finally:\n",
        "    try:\n",
        "        root.attributes('-topmost', False)\n",
        "        root.destroy()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "# ====== 3. DATA CLEANING (drop duplicates + mild outlier removal) ======\n",
        "try:\n",
        "    df = df.drop_duplicates()\n",
        "\n",
        "    # IQR outlier filter (mild)\n",
        "    for col in [x_col, y_col]:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower = Q1 - 1.5 * IQR\n",
        "        upper = Q3 + 1.5 * IQR\n",
        "        df = df[(df[col] >= lower) & (df[col] <= upper)]\n",
        "\n",
        "    df = df.reset_index(drop=True)\n",
        "    if df.empty:\n",
        "        raise ValueError(\"All rows removed by cleaning; relax outlier filter.\")\n",
        "    print(\"\\nData cleaned successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error cleaning data: {e}\")\n",
        "\n",
        "# ====== 4. NORMALIZE (store original stats) ======\n",
        "try:\n",
        "    x_mean_original = df[x_col].mean()\n",
        "    x_std_original  = df[x_col].std()\n",
        "    y_mean_original = df[y_col].mean()\n",
        "    y_std_original  = df[y_col].std()\n",
        "\n",
        "    if np.isclose(x_std_original, 0.0) or np.isclose(y_std_original, 0.0):\n",
        "        raise ValueError(\"Std of X or Y is zero; cannot normalize.\")\n",
        "\n",
        "    df['X_norm'] = (df[x_col] - x_mean_original) / x_std_original\n",
        "    df['Y_norm'] = (df[y_col] - y_mean_original) / y_std_original\n",
        "\n",
        "    print(\"\\nNormalization complete!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error in normalization: {e}\")\n",
        "\n",
        "# ====== 5. SHUFFLE & SPLIT ======\n",
        "try:\n",
        "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    train_frac = 1.0  # set to 0.8 if you want a test set\n",
        "    train_size = int(train_frac * len(df))\n",
        "    train_data = df.iloc[:train_size].copy()\n",
        "    test_data  = df.iloc[train_size:].copy()\n",
        "\n",
        "    X_train = train_data['X_norm'].to_numpy()\n",
        "    y_train = train_data['Y_norm'].to_numpy()\n",
        "    X_test  = test_data['X_norm'].to_numpy()\n",
        "    y_test  = test_data['Y_norm'].to_numpy()\n",
        "\n",
        "    print(f\"\\nData split: Train={len(train_data)}, Test={len(test_data)}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error splitting data: {e}\")\n",
        "\n",
        "# ====== 6. GRADIENT DESCENT ======\n",
        "theta_0 = 0.0\n",
        "theta_1 = 0.0\n",
        "try:\n",
        "    alpha = 0.01\n",
        "    m = len(X_train)\n",
        "    epochs = 0\n",
        "    max_epochs = 5000\n",
        "    tolerance = 0\n",
        "    prev_cost = float('inf')\n",
        "\n",
        "    while epochs < max_epochs:\n",
        "        y_pred = theta_0 + theta_1 * X_train\n",
        "        error = y_pred - y_train\n",
        "        cost = (1 / (2 * m)) * np.sum(error ** 2)\n",
        "\n",
        "        if abs(prev_cost - cost) < tolerance:\n",
        "            print(f\"\\nConverged at epoch {epochs}, cost={cost}\")\n",
        "            break\n",
        "        prev_cost = cost\n",
        "\n",
        "        d_theta0 = (1/m) * np.sum(error)\n",
        "        d_theta1 = (1/m) * np.sum(error * X_train)\n",
        "\n",
        "        theta_0 -= alpha * d_theta0\n",
        "        theta_1 -= alpha * d_theta1\n",
        "        epochs += 1\n",
        "\n",
        "        if epochs % 500 == 0:\n",
        "            print(f\"Epoch {epochs}, Cost={cost}\")\n",
        "\n",
        "    print(f\"\\nTraining complete in {epochs} epochs\")\n",
        "    print(f\"θ0 (intercept): {theta_0}\")\n",
        "    print(f\"θ1 (slope): {theta_1}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during training: {e}\")\n",
        "\n",
        "# ====== 6b. STORE MODEL SAFELY ======\n",
        "model_id = None\n",
        "try:\n",
        "    storage = ModelStorage()  # default: 1models.db in current directory\n",
        "    model_id = storage.add_model(\n",
        "        user_id=\"alice14423\",      # TODO: replace with real logged-in user id\n",
        "        file_path=file_name,     # actual selected file\n",
        "        x_col=x_col,\n",
        "        y_col=y_col,\n",
        "        theta0=theta_0,\n",
        "        theta1=theta_1,\n",
        "        epochs=epochs,\n",
        "        tolerance=float(tolerance)\n",
        "    )\n",
        "    print(f\"\\nModel stored with ID: {model_id}\")\n",
        "    # Optional: fetch back to verify\n",
        "    rec = storage.get_model(model_id)\n",
        "    print(f\"🔎 Stored row: {rec}\")\n",
        "except Exception as db_err:\n",
        "    print(f\"\\nFailed to store model in DB: {db_err}\")\n",
        "finally:\n",
        "    try:\n",
        "        storage.close()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "# ====== 7. TESTING ======\n",
        "try:\n",
        "    if len(X_test) > 0:\n",
        "        y_test_pred = theta_0 + theta_1 * X_test\n",
        "        mse_test = (1 / len(X_test)) * np.sum((y_test_pred - y_test) ** 2)\n",
        "        print(f\"\\nTest MSE (normalized space): {mse_test}\")\n",
        "    else:\n",
        "        print(\"\\nNo test set (all data used for training).\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during testing: {e}\")\n",
        "\n",
        "# ====== 8. PREDICTION FUNCTION ======\n",
        "def predict_single(raw_x: float) -> float:\n",
        "    norm_x = (raw_x - x_mean_original) / x_std_original\n",
        "    norm_y_pred = theta_0 + theta_1 * norm_x\n",
        "    raw_y_pred = (norm_y_pred * y_std_original) + y_mean_original\n",
        "    return float(raw_y_pred)\n",
        "\n",
        "# Example predictions\n",
        "try:\n",
        "    test_values = [10, 20, 50]\n",
        "    print(\"\\nPredictions:\")\n",
        "    for val in test_values:\n",
        "        print(f\"X={val} → Predicted Y={predict_single(val)}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during prediction: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D_aC877_7s3"
      },
      "source": [
        "Final Predictions using scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "DL0XrkU8AVBq",
        "outputId": "8f77cf1b-0cc0-4dfe-a60b-d97c85de52c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n",
            "CSV loaded successfully!\n",
            "Data cleaned successfully! Only numeric rows remain.\n",
            "Data split into training/testing sets!\n",
            "Z-score normalization done (original values preserved)!\n",
            "Training complete!\n",
            "Intercept (θ0): 0.0\n",
            "Slope (θ1): 1.0\n",
            "Test MSE (normalized space): 0.0\n",
            "Predicted Y (normalized): -1.8380814494296098\n",
            "Predicted Y (original scale): 8.0\n"
          ]
        }
      ],
      "source": [
        "# ====== 1. IMPORT LIBRARIES ======\n",
        "try:\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from tkinter import filedialog\n",
        "    import tkinter as tk\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    print(\"Libraries imported successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error importing libraries: {e}\")\n",
        "\n",
        "# ====== 2. LOAD CSV ======\n",
        "try:\n",
        "    # Create a Tkinter root window\n",
        "    root = tk.Tk()\n",
        "    root.withdraw()\n",
        "    root.attributes('-topmost', True)\n",
        "    root.update()\n",
        "    root.after(100)\n",
        "\n",
        "    # Open a file picker dialog to select the CSV file\n",
        "    file_name = filedialog.askopenfilename(filetypes=[(\"CSV files\", \"*.csv\")])\n",
        "    if not file_name:\n",
        "        raise FileNotFoundError(\"No file selected.\")\n",
        "    \n",
        "    # Read the CSV file using pandas\n",
        "    df = pd.read_csv(file_name)\n",
        "    print(\"CSV loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"CSV file not found. Please select a valid CSV file.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error reading CSV: {e}\")\n",
        "finally:\n",
        "    root.attributes('-topmost', False)\n",
        "    root.destroy()\n",
        "\n",
        "# ====== 3. DATA CLEANING ======\n",
        "try:\n",
        "    df = df.drop_duplicates()\n",
        "    df = df.dropna()\n",
        "\n",
        "    # Keep only numeric rows\n",
        "    numeric_df = pd.DataFrame()\n",
        "    for col in df.columns:\n",
        "        numeric_df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df = numeric_df.dropna()\n",
        "\n",
        "    print(\"Data cleaned successfully! Only numeric rows remain.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error cleaning data: {e}\")\n",
        "\n",
        "# ====== 4. SPLIT DATA INTO TRAIN / TEST ======\n",
        "try:\n",
        "    X = df[['X']].values  # scikit-learn expects 2D array for features\n",
        "    y = df['Y'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "    print(\"Data split into training/testing sets!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error splitting data: {e}\")\n",
        "\n",
        "# ====== 5. FEATURE SCALING (Z-score normalization) ======\n",
        "try:\n",
        "    scaler_X = StandardScaler()\n",
        "    scaler_y = StandardScaler()\n",
        "\n",
        "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "    y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).ravel()  # flatten y\n",
        "\n",
        "    X_test_scaled = scaler_X.transform(X_test)\n",
        "    y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).ravel()\n",
        "\n",
        "    print(\"Z-score normalization done (original values preserved)!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during normalization: {e}\")\n",
        "\n",
        "# ====== 6. TRAIN LINEAR REGRESSION ======\n",
        "try:\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "    print(f\"Training complete!\")\n",
        "    print(f\"Intercept (θ0): {model.intercept_}\")\n",
        "    print(f\"Slope (θ1): {model.coef_[0]}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during training: {e}\")\n",
        "\n",
        "# ====== 7. TESTING ======\n",
        "try:\n",
        "    y_test_pred_scaled = model.predict(X_test_scaled)\n",
        "    mse_test = mean_squared_error(y_test_scaled, y_test_pred_scaled)\n",
        "    print(f\"Test MSE (normalized space): {mse_test}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during testing: {e}\")\n",
        "\n",
        "# ====== 8. PREDICT FOR A SINGLE USER-INPUT VALUE ======\n",
        "try:\n",
        "    raw_x = float(input(\"Enter the value of X (original/raw value): \"))\n",
        "\n",
        "    # Normalize input using scaler\n",
        "    norm_x = scaler_X.transform([[raw_x]])\n",
        "    norm_y_pred = model.predict(norm_x)\n",
        "\n",
        "    # Convert prediction back to original scale\n",
        "    raw_y_pred = scaler_y.inverse_transform(norm_y_pred.reshape(-1, 1))[0, 0]\n",
        "\n",
        "    print(f\"Predicted Y (original scale): {raw_y_pred}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during prediction: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
